{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from string import Template\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "import glob\n",
    "from timeit import default_timer as timer\n",
    "from dotenv import load_dotenv\n",
    "from time import sleep\n",
    "\n",
    "from prompts import IS_SAME_LABEL_PROMPT\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Openai configuration\n",
    "openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "azure_endpoint=os.getenv(\"OPENAI_ENDPOINT\")\n",
    "openai_api_version=os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai_model=os.getenv(\"OPENAI_MODEL\")\n",
    "\n",
    "client = AzureOpenAI(  \n",
    "    api_key=openai_api_key,\n",
    "    azure_endpoint=azure_endpoint,  \n",
    "    api_version=openai_api_version,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call OpenAi\n",
    "def process_gpt(file_prompt, system_msg):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=openai_model,\n",
    "        max_tokens=15000,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": file_prompt},\n",
    "        ],\n",
    "    )\n",
    "    nlp_results = completion.choices[0].message.content\n",
    "    return nlp_results\n",
    "\n",
    "def matches_label(labels, label):\n",
    "    for other in labels:\n",
    "        if label['name'] == other['name'] and label['description'] == other['description']:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def matches_rels(rels, rel):\n",
    "    for other in rels:\n",
    "        if rel == other:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Function to create list of labels and relationships that differ\n",
    "def primitive_prune(detailed):\n",
    "    labels = []\n",
    "    rels = []\n",
    "    for detail in detailed:\n",
    "        for label in detail[\"labels\"]:\n",
    "            if not matches_label(labels, label): labels.append(label)\n",
    "        \n",
    "        for rel in detail[\"relationships\"]:\n",
    "            if not matches_rels(rels, rel): rels.append(rel)\n",
    "\n",
    "    result = {\n",
    "        \"labels\": labels,\n",
    "        \"relationships\": rels\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "# Function to check if is same label semantically\n",
    "def is_same_label(label1: dict, label2: dict) -> bool:\n",
    "    label1Name = label1[\"name\"]\n",
    "    label1Description = label1[\"description\"]\n",
    "    label2Name = label2[\"name\"]\n",
    "    label2Description = label2[\"description\"]\n",
    "    system_msg = \"You are a helpful IT-project that decides wether or not two objects are the same and return 0 to indicate no match and 1 to indicate match.\"\n",
    "    file_prompt = Template(IS_SAME_LABEL_PROMPT).substitute(obj1Name=label1Name, obj1Description=label1Description, obj2Name=label2Name, obj2Description=label2Description)\n",
    "\n",
    "    result = process_gpt(file_prompt, system_msg)\n",
    "    \n",
    "    if result == '0': return False\n",
    "    if result == '1': return True\n",
    "    raise Exception(\"OpenAi did not return 0 or 1\")\n",
    "\n",
    "# Function to create list of labels that are semantically different\n",
    "def prune_semantically(labels: list[dict]):\n",
    "    print(\"labels: \", labels)\n",
    "    label_groups = []\n",
    "    for label in labels:\n",
    "        print(\"label: \", label)\n",
    "        is_in_group = False\n",
    "        for group in label_groups:\n",
    "            if label[\"name\"] == group[\"name\"]:\n",
    "                is_in_group = True\n",
    "                group[\"labels\"].append(label)\n",
    "                break\n",
    "        \n",
    "        if not is_in_group:\n",
    "            label_groups.append({\n",
    "                \"name\": label[\"name\"],\n",
    "                \"labels\": [label]\n",
    "            })\n",
    "\n",
    "    for group in label_groups:\n",
    "        labels = group[\"labels\"]\n",
    "        distinct_labels = []\n",
    "        print(\"prune group: \", group)\n",
    "        start = timer()\n",
    "        while len(labels) > 0:\n",
    "            label = labels[0]\n",
    "            distinct_labels.append(label)\n",
    "            del labels[0]\n",
    "            labels = list(filter(lambda other: not is_same_label(label, other), labels))\n",
    "        end = timer()\n",
    "        print(f\"{end-start}s\")\n",
    "        group[\"labels\"] = distinct_labels\n",
    "\n",
    "    all = []\n",
    "    for group in label_groups:\n",
    "        all += group[\"labels\"]\n",
    "\n",
    "    return all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labe:  labels\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mprimitively_pruned.json\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      2\u001b[39m     labels = json.load(f)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m result = \u001b[43mprune_semantically\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33msemanticly_pruned.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m r:\n\u001b[32m      7\u001b[39m     json.dump(result, r)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mprune_semantically\u001b[39m\u001b[34m(labels)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_in_group:\n\u001b[32m     75\u001b[39m         label_groups.append({\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mlabel\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m     77\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m: [label]\n\u001b[32m     78\u001b[39m         })\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m label_groups:\n\u001b[32m     81\u001b[39m     labels = group[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mTypeError\u001b[39m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "with open(\"primitively_pruned.json\") as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "result = prune_semantically(labels)\n",
    "\n",
    "with open(\"semanticly_pruned.json\", \"w\") as r:\n",
    "    json.dump(result, r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
